{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy86JeXPHQmW"
      },
      "source": [
        "# InvokeAI in Google Colab\n",
        "\n",
        "###Introduction\n",
        "\n",
        "This is a tool to use Google Colab to run the AI image generation tool: Invokeai (https://invoke-ai.github.io/InvokeAI/). <br />\n",
        "This can save the generated images in Google Drive or work purely in the runtime. <br />\n",
        "You can optionally save your models in Google Drive too, This takes up far more space but makes resuming generation very simple. <br />\n",
        "\n",
        "A GPU should be enabled by default, but if not the setting can be found in the menu under: Edit > Notebook Settings > Hardware accelerator > T4 GPU\n",
        "\n",
        "To start, Click \"Runtime\" > \"Run All\". Alternatively you can click the \"play\" button on each step below sequentially; there's no need to wait for a step to complete before starting the next, as they will be added to an execution queue.\n",
        "\n",
        "This uses the \"Low VRAM mode\" included with InvokeAI 5.5.0+"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cEAEBY2sFdGR"
      },
      "outputs": [],
      "source": [
        "#@title 1. Configuration { display-mode: \"form\" }\n",
        "#@markdown #Instance Type\n",
        "#@markdown **Google_Drive** = Stores Models, Images and the database in your Google drive, the space it takes up is heavily based on the type and number of models that you are using. <br>\n",
        "#@markdown **Temporary** = Everything is stored in the runtime and is removed when the runtime ends or crashes, make sure to download your images! <br>\n",
        "Type = \"Google_Drive\" #@param ['Google_Drive','Temporary'] {type:\"string\"}\n",
        "#@markdown If using \"Google Drive\" mode, where do you want the models saved to? <br>\n",
        "#@markdown I recommend also using Google_Drive, however if you have limited space and want to only save images to Drive, you can change that here!\n",
        "Models = \"Google_Drive\" #@param ['Google_Drive','Temporary'] {type:\"string\"}\n",
        "#@markdown Note: if you don't save models to drive and you re-load the same instance the models will think they are still there, you have to remove + re-download them.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown #Connection Type.\n",
        "#@markdown **NGROK**: (Recommended) Highly stable but needs a little setting up, An NGROK token is required, sign up for free and get one here: https://dashboard.ngrok.com/get-started/your-authtoken - Once you have the token, please put it in below.<br>\n",
        "#@markdown **NGROK_APT**: An alternate version of NGROK that runs as a Linux service rather than a python service.<br>\n",
        "#@markdown **Localtunnel**: Slower than NGROK and more often has issues, but will just work, no token or configuration needed.<br>\n",
        "connection_type = \"Localtunnel\"  #@param [\"Localtunnel\",\"NGROK\",\"NGROK_APT\"]\n",
        "ngrok_token = \"None\" #@param ['None'] {allow-input: true}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #Instance Selector.\n",
        "#@markdown If you would like to have more than one instance of InvokeAI so you can keep things separate you can do this here: <br>\n",
        "#@markdown \"Default\" Keeps the files either in /content/invokeai or /content/drive/MyDrive/InvokeAI <br>\n",
        "#@markdown Changing this to anything else puts the files in a sub-folder of that location called \"CustomInstances\" and then the Instance name.\n",
        "Instance = \"Default\"  #@param [\"Default\",\"Anime\",\"Photorealism\"] {allow-input: true}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #InvokeAi Version.\n",
        "#@markdown The default version is \"the latest stable release of InvokeAI\" If you want to specify a specific version, please input that here:. <br>\n",
        "#@markdown Any version 5.7.2+ should work with all features, anything before 5.0.0 will probably not work at all.\n",
        "version = \"Default\"  #@param [\"Default\",\"5.7.2\",\"5.6.1\"] {allow-input: true}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #Model Management.\n",
        "#@markdown All model management is all done in-app, the \"Model Manager\" is found on the left hand side once you are in the app. <br />\n",
        "#@markdown If you are using Temporary Mode, and want to attach Google Drive purely to import models from, tick this box.\n",
        "GDrive_Import = False #@param {type: \"boolean\"}\n",
        "#@markdown The path to the root of your Google drive will be added as: /content/drive/MyDrive/ You will use that in the \"Model manager\" to import models.\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #Memory Management.\n",
        "#@markdown InvokeAI offers two memory allocator methods to load and manage models in VRAM. Typically, the CUDA allocator outperforms the pytorch allocator, reducing peak VRAM usage. In most cases, CUDA should improve generation speeds. <br />\n",
        "#@markdown Note: InvokeAI Version 5.7.2+ only (Please use 'pytorch' for older versions) <br />\n",
        "#@markdown Note2: If you for whatever reason want to use CPU mode... Please choose \"pytorch\" as CUDA will not work.\n",
        "MemoryManagementMethod = \"CUDA\"  #@param [\"CUDA\",\"pytorch\"]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Installation. { display-mode: \"form\" }\n",
        "#@markdown Install InvokeAI and configure it as requested, This takes around 4-5 mins.\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "#Setting File Path\n",
        "file_path = '/content/invokeai'\n",
        "\n",
        "#Set up temporary storage if running in \"Temporary\" mode.\n",
        "if Type == \"Temporary\":\n",
        "    import os\n",
        "    if not os.path.exists(file_path):\n",
        "      os.makedirs(file_path)\n",
        "\n",
        "    #Mount google drive for model imports if requested.\n",
        "    if GDrive_Import == True:\n",
        "      import os\n",
        "      from google.colab import drive\n",
        "      if not os.path.exists('/content/drive/'):\n",
        "        print(\"Connecting to Google Drive, please log in using the pop-up window.\")\n",
        "        drive.mount('/content/drive')\n",
        "      print(\"Connected!\")\n",
        "\n",
        "# Mount and set up Google drive if running in \"Google_Drive\" mode.\n",
        "if Type == \"Google_Drive\":\n",
        "  import os\n",
        "  from google.colab import drive\n",
        "  if not os.path.exists(file_path):\n",
        "    print(\"Connecting to Google Drive, please log in using the pop-up window.\")\n",
        "    drive.mount('/content/drive')\n",
        "    if not os.path.exists(file_path):\n",
        "      os.makedirs(file_path)\n",
        "  print(\"Connected!\")\n",
        "\n",
        "#set working DIR\n",
        "%cd {file_path}\n",
        "\n",
        "#Clear Output\n",
        "clear_output()\n",
        "\n",
        "print(\"=======================\")\n",
        "print(\"|Install Dependencies.|\")\n",
        "print(\"=======================\")\n",
        "\n",
        "#Update pip\n",
        "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "!python -m pip install --upgrade pip\n",
        "\n",
        "#Create InvokeAI root\n",
        "import os\n",
        "os.environ['INVOKEAI_ROOT'] = file_path\n",
        "if not os.path.exists(file_path):\n",
        "  os.makedirs(file_path)\n",
        "\n",
        "#Confirm that This is working in the correct place.\n",
        "%cd {file_path}\n",
        "\n",
        "#Clear Output\n",
        "clear_output()\n",
        "\n",
        "\n",
        "print(\" \")\n",
        "print(\"======================\")\n",
        "print(\"|1. Install InvokeAI.|\")\n",
        "print(\"======================\")\n",
        "\n",
        "#Version selector\n",
        "if version == \"Default\":\n",
        "  print(\" \")\n",
        "  print(\"Installing the Latest stable release of InvokeAI. This may take 4-5 minutes. Please be patient...\")\n",
        "  !pip install invokeai[xformers] &> /dev/null\n",
        "  print(\"Installation command issued.\")\n",
        "if version != \"Default\":\n",
        "  print(\" \")\n",
        "  print(f\"Installing InvokeAI version: {version}. This may take 4-5 minutes. Please be patient...\")\n",
        "  !pip install invokeai[xformers]=={version} &> /dev/null\n",
        "  print(\"Installation command issued.\")\n",
        "\n",
        "print(\" \")\n",
        "print(\"App Installed.\")\n",
        "\n",
        "#This 'Deactivate' is needed in case you run this twice in one session where an update is released between runs, it will error 99% of the time.\n",
        "if os.path.exists(\"/content/RunSuccess\"):\n",
        "  print(\" \")\n",
        "  print(\"This Deactivate only is needed on subsequent runs. Ignore that it has errored. It will most of the time, and is a cleanup.\")\n",
        "  !deactivate\n",
        "  print(\"Deactivate command has been executed.\")\n",
        "if not os.path.exists(\"/content/RunSuccess\"):\n",
        "  !touch \"/content/RunSuccess\"\n",
        "\n",
        "print(\" \")\n",
        "print(\"Expected Error saying path does not exist:\") # Removed extra space\n",
        "!source .venv/bin/activate\n",
        "\n",
        "\n",
        "print(\" \")\n",
        "print(\"========================\")\n",
        "print(\"|2. Configure InvokeAI.|\")\n",
        "print(\"========================\")\n",
        "\n",
        "#Settings for ALL instances.\n",
        "!echo \"# Internal metadata - do not edit:\" > /content/invokeai/invokeai.yaml\n",
        "!echo \"schema_version: 4.0.2\" >> /content/invokeai/invokeai.yaml\n",
        "!echo \" \" >> /content/invokeai/invokeai.yaml\n",
        "!echo \"# Put user settings here - see https://invoke-ai.github.io/InvokeAI/configuration/\" >> /content/invokeai/invokeai.yaml\n",
        "\n",
        "#Default Instance location.\n",
        "if Instance == \"Default\":\n",
        "  if Type == \"Google_Drive\":\n",
        "    print(\" \")\n",
        "    print(\"Configuring the runtime for 'Google Drive' storage.\")\n",
        "\n",
        "    if Models == \"Google_Drive\":\n",
        "      !echo \"models_dir: /content/drive/MyDrive/InvokeAI/Models\" >> /content/invokeai/invokeai.yaml\n",
        "    !echo \"outputs_dir: /content/drive/MyDrive/InvokeAI\" >> /content/invokeai/invokeai.yaml\n",
        "    !echo \"db_dir: /content/drive/MyDrive/InvokeAI/DB\" >> /content/invokeai/invokeai.yaml\n",
        "    !echo \"enable_partial_loading: true\" >> /content/invokeai/invokeai.yaml\n",
        "    if MemoryManagementMethod == \"CUDA\":\n",
        "      !echo \"pytorch_cuda_alloc_conf: \\\"backend:cudaMallocAsync\\\"\" >> /content/invokeai/invokeai.yaml\n",
        "    print(\" \")\n",
        "    print(\"Locations set for Google Drive!\")\n",
        "\n",
        "  if Type == \"Temporary\":\n",
        "    print(\" \")\n",
        "    print(\"Configuring the runtime for 'Temporary' storage.\")\n",
        "\n",
        "    !echo \"enable_partial_loading: true\" >> /content/invokeai/invokeai.yaml\n",
        "    if MemoryManagementMethod == \"CUDA\":\n",
        "      !echo \"pytorch_cuda_alloc_conf: \\\"backend:cudaMallocAsync\\\"\" >> /content/invokeai/invokeai.yaml\n",
        "    print(\" \")\n",
        "    print(\"Locations set for Temporary Storage!\")\n",
        "\n",
        "#Non-Default Instance location.\n",
        "if Instance != \"Default\":\n",
        "  if Type == \"Google_Drive\":\n",
        "    print(\" \")\n",
        "    print(\"Configuring the runtime for 'Google Drive' storage, with custom instance.\")\n",
        "    print(\" \")\n",
        "    print(\"Instance name:\")\n",
        "    print(Instance)\n",
        "\n",
        "    if Models == \"Google_Drive\":\n",
        "      !echo \"models_dir: /content/drive/MyDrive/InvokeAI/CustomInstances/{Instance}/Models\" >> /content/invokeai/invokeai.yaml\n",
        "    !echo \"outputs_dir: /content/drive/MyDrive/InvokeAI/CustomInstances/{Instance}\" >> /content/invokeai/invokeai.yaml\n",
        "    !echo \"db_dir: /content/drive/MyDrive/InvokeAI/CustomInstances/{Instance}/DB\" >> /content/invokeai/invokeai.yaml\n",
        "    !echo \"enable_partial_loading: true\" >> /content/invokeai/invokeai.yaml\n",
        "    if MemoryManagementMethod == \"CUDA\":\n",
        "      !echo \"pytorch_cuda_alloc_conf: \\\"backend:cudaMallocAsync\\\"\" >> /content/invokeai/invokeai.yaml\n",
        "    print(\" \")\n",
        "    print(\"Locations set for Google Drive!\")\n",
        "\n",
        "\n",
        "  if Type == \"Temporary\":\n",
        "    print(\" \")\n",
        "    print(\"Configuring the runtime for 'Temporary' storage, with custom instance.\")\n",
        "    print(\" \")\n",
        "    print(\"Instance name:\")\n",
        "    print(Instance)\n",
        "\n",
        "    !echo \"models_dir: /content/invokeai/CustomInstances/{Instance}/Models\" >> /content/invokeai/invokeai.yaml\n",
        "    !echo \"outputs_dir: /content/invokeai/CustomInstances/{Instance}\" >> /content/invokeai/invokeai.yaml\n",
        "    !echo \"db_dir: /content/invokeai/CustomInstances/{Instance}/DB\" >> /content/invokeai/invokeai.yaml\n",
        "    !echo \"enable_partial_loading: true\" >> /content/invokeai/invokeai.yaml\n",
        "    if MemoryManagementMethod == \"CUDA\":\n",
        "      !echo \"pytorch_cuda_alloc_conf: \\\"backend:cudaMallocAsync\\\"\" >> /content/invokeai/invokeai.yaml\n",
        "    print(\" \")\n",
        "    print(\"Locations set for Temporary Storage!\")\n",
        "\n",
        "#Misc Fixes\n",
        "print(\" \")\n",
        "print(\"================\")\n",
        "print(\"|3. Misc Fixes.|\")\n",
        "print(\"================\")\n",
        "\n",
        "#Reinstall some features.\n",
        "print(\" \")\n",
        "print(\"Reinstalling some pip modules to make sure they function correctly.\")\n",
        "\n",
        "#These ones were previously needed but break things now, leaving as comment for now.\n",
        "#!pip uninstall -y opentelemetry-api opentelemetry-sdk opentelemetry-exporter-otlp pydantic &> /dev/null\n",
        "#!pip install opentelemetry-api opentelemetry-sdk opentelemetry-exporter-otlp pydantic &> /dev/null\n",
        "\n",
        "!pip uninstall -y fastapi-events fastapi &> /dev/null\n",
        "!pip install fastapi-events fastapi &> /dev/null\n",
        "!pip install --upgrade jax_cuda12_plugin &> /dev/null\n",
        "\n",
        "\n",
        "#Success message\n",
        "print(\" \")\n",
        "print(\"================================\")\n",
        "print(\"|5. Done! Launch the app below!|\")\n",
        "print(\"================================\")\n",
        "print(\" \")\n",
        "print(\"Note: When you start the app, it may throw the error shown below. This is often benign, and the application should still function correctly. Please ignore this specific error if the app works.\")\n",
        "print(\"/bin/bash: line 1: /content/invokeai/.venv/bin/activate: No such file or directory\")\n",
        "\n"
      ],
      "metadata": {
        "id": "NO3XyDPsTJ2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnO01U-W6Yjp"
      },
      "outputs": [],
      "source": [
        "#@title 3. Start InvokeAI. { display-mode: \"form\" }\n",
        "#@markdown ## Starting the App\n",
        "#@markdown This step takes about 15 seconds to generate your URL but 30 seconds after it is launched before it will work fully! <br>\n",
        "\n",
        "#@markdown ## Notes about connection types.\n",
        "#@markdown **NGROK** (Recommended) = Very stable but requires a token, see the \"configuration\" step for more details.<br>\n",
        "#@markdown **NGROK_APT** = An alternate version of NGROK that runs using the system packages rather than Python. <br>\n",
        "#@markdown **Localtunnel** = Once it gets going it is quite stable but often has \"502\" Errors, You must wait for the Localtunnel service to resolve the issue, or try another connection type.<br>\n",
        "\n",
        "#@markdown Note: If you are using \"Google_Drive\" It is STRONGLY recommended to stop this step from running when you have finished, so it gracefully shuts down.<br>\n",
        "#@markdown If you just \"Disconnect and Delete this runtime\" it may cause some corruption if all information has not finished being uploaded to your drive yet.\n",
        "\n",
        "!source .venv/bin/activate\n",
        "\n",
        "%cd {file_path}\n",
        "import os\n",
        "\n",
        "#Clear Output\n",
        "clear_output()\n",
        "\n",
        "if connection_type == \"Localtunnel\":\n",
        "  print(\"How to connect to localtunnel:\")\n",
        "  print(\"A localtunnel Interface connection is generated here, To use this, please do the following:\")\n",
        "  print(\"1. Copy this IP address\")\n",
        "  !curl ipv4.icanhazip.com\n",
        "  print(\"2. Click the random 'https://XXX-YYY-ZZZ.loca.lt' link that is generated below.\")\n",
        "  print(\"3. Paste the IP into the provided box and submit. \")\n",
        "  print(\" \")\n",
        "  print(\"Note: An error of '502 Bad Gateway' typically is an error at Localtunnel's end. A '504 Gateway Time-out' Error means invokeai has not started yet.\")\n",
        "  print(\" \")\n",
        "  !npm install -g localtunnel\n",
        "  !lt --port 9090 & ! . {file_path}/.venv/bin/activate; invokeai-web\n",
        "\n",
        "\n",
        "#NGROK_Python\n",
        "if connection_type == \"NGROK\":\n",
        "  if ngrok_token == \"None\":\n",
        "    print(\"You have selected NGROK but did not supply an NGROK token.\")\n",
        "    print(\"Falling back to a 'Localtunnel' connection type.\")\n",
        "    print(\"Please either add an NGROK token to step 1, re-run step 1, then re-run this step, or just re-run this step to use 'Localtunnel'.\")\n",
        "    connection_type = \"Localtunnel\"\n",
        "  if ngrok_token != \"None\":\n",
        "    !pip install pyngrok --quiet\n",
        "    from pyngrok import ngrok\n",
        "    ngrok.kill()\n",
        "    ngrok.set_auth_token(ngrok_token)\n",
        "    public_url = ngrok.connect(9090).public_url\n",
        "    print(f'InvokeAI Public URL: {public_url}')\n",
        "    ! . {file_path}/.venv/bin/activate; invokeai-web\n",
        "\n",
        "#NGROK_APT\n",
        "if connection_type == \"NGROK_APT\":\n",
        "  if ngrok_token == \"None\":\n",
        "    print(\"You have selected NGROK but did not supply an NGROK token.\")\n",
        "    print(\"Falling back to a 'Localtunnel' connection type.\")\n",
        "    print(\"Please either add an NGROK token to step 1, re-run step 1, then re-run this step, or just re-run this step to use 'Localtunnel'.\")\n",
        "    connection_type = \"Localtunnel\"\n",
        "  if ngrok_token != \"None\":\n",
        "    !curl -sSL https://ngrok-agent.s3.amazonaws.com/ngrok.asc | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null\n",
        "    !echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" | sudo tee /etc/apt/sources.list.d/ngrok.list\n",
        "    !sudo apt update\n",
        "    !sudo apt install ngrok\n",
        "    !ngrok config add-authtoken {ngrok_token}\n",
        "    clear_output()\n",
        "    !echo \"You can find the connection URL here in the NGROK portal:\"\n",
        "    !echo \" https://dashboard.ngrok.com/endpoints\" # Added space\n",
        "    !nohup ngrok http http://localhost:9090 &\n",
        "    ! . {file_path}/.venv/bin/activate; invokeai-web"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training<br />\n",
        "hollowstrawberry has an amazing Google Colab LoRA maker, it is much better than I could do! It can be found here:<br />\n",
        "Dataset Maker - https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb <br />\n",
        "LoRA Trainer - https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb"
      ],
      "metadata": {
        "id": "hVrwuBg_gp-e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FAQ:\n",
        "\n",
        "## Images are taking a LONG time to generate. (~30 mins for a 512x512 image.)\n",
        "You may have used up your compute allowance and are running in CPU mode. While this is running, clicking the \"RAM / Disk\" button in the top right to see if it lists \"GPU RAM\". If not, you are not connected to a GPU instance.\n",
        "or maybe, you have the GPU turned off, check \"Edit > Notebook settings\" to make sure a GPU is selected. (\"T4 GPU\" is the current default)\n",
        "\n",
        "## It is taking a while to even start loading.\n",
        "If you have started a new instance / are changing a model, the model needs to be loaded into Invoke. If you are using \"Google Drive\" it has to download the model to the runtime, this can take a while especially for XL (5-10 mins) or FLUX models (20+ mins).\n",
        "\n",
        "##No link is given to me?\n",
        "You can check the status of the service at one of these two pages. <br>\n",
        "Localtunnel: https://downforeveryoneorjustme.com/localtunnel.me <br>\n",
        "NGROK: https://status.ngrok.com\n",
        "\n",
        "\n",
        "## I get an error \"You have recently exceeded an allowance, most recently at (Time)\"\n",
        "This is typically when you have exceeded some Google restriction(s). This is most common when you stop / start instances frequently and often does not affect anything. <br>\n",
        "If it is blocking things, you typically have to wait 1 hour for soft allowances to reset.\n",
        "\n",
        "##How much longer can my instance run for today?\n",
        "If you click the \"RAM / Disk\" button in the top right it will tell you something like \"At your current usage level, this runtime may last up to 1 hour 20 minutes\"\n",
        "\n",
        "## My instance disconnects while I'm using it.\n",
        "Technically using Web interface to run programs in a way like this project does, is against Google Colab's Terms of Service. If you don't look at this tab for 15+ minutes it may hibernate. Simply flick back to this tab on a semi-regular basis to keep it active!\n",
        "\n",
        "## Are there any known issues?\n",
        "If there are, I will typically update the header at the top of this page above the \"Introduction\".\n",
        "\n",
        "## I want to make my own changes to this file, and save them.\n",
        "Feel free to! \"File > Save a copy in drive\" is the safest way to do this.\n",
        "\n",
        "## Is this maintained frequently?\n",
        "I am a solo developer that maintains it the best that I can, I do use this project frequently so hopefully I will notice any major issues. <br>\n",
        "If you have any issues you can raise them on Github, I will deal with them when I can! <br>\n",
        "https://github.com/MikeEmmett/InvokeAI/issues\n",
        "\n",
        "## I am using Google Drive and I want to reset everything.\n",
        "If you log onto https://drive.google.com/drive/my-drive with your Google account you will find a folder called \"InvokeAI\" <br>\n",
        "If you just want to reset it without keeping anything, simply delete the whole folder. <br>\n",
        "If you want to reset it but keep the models / Images in an archive, rename the folder.\n",
        "\n",
        "## I don't understand the options above...\n",
        "Experiment! This will work fully if you just do \"Runtime > Run all\". It will connect to your Google Drive and spin up a \"Localtunnel\" connection, and you simply copy the IP address / paste into the link as instructed in the last step! Also feel free to play around, you can't break things permanently!"
      ],
      "metadata": {
        "id": "2dccS8zX9wHK"
      }
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}