{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy86JeXPHQmW"
      },
      "source": [
        "# InvokeAI in Google Colab\n",
        "\n",
        "## This version for 5.6.0+, This has had a major update since the PRE-5.5.0 version. Images or models will not migrate between the old and the new versions of this colab.\n",
        "\n",
        "###Introduction\n",
        "\n",
        "This is a tool to use Google colab to run the AI image generation tool: Invokeai (https://invoke-ai.github.io/InvokeAI/).\n",
        "This automatically builds itself, It can connect to Google drive to save your images.\n",
        "It also has the option of running from Google Drive, This takes about 2GB + Models of Google Drive space.\n",
        "\n",
        "Make sure to enable GPU This should be on by default, but the setting can be found in the menu under: Edit > Notebook Settings > Hardware accelerator > GPU\n",
        "\n",
        "To start, Click \"Runtime\" > \"Run All\". Alternaivly you can click the \"play\" button on each step below one after the other, No need to wait for the previous steps to finish as they will join a queue.\n",
        "\n",
        "This uses the \"Low VMRAM move\" included with InvokeAI 5.5.0+"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cEAEBY2sFdGR"
      },
      "outputs": [],
      "source": [
        "#@title 1. Configuration { display-mode: \"form\" }\n",
        "#@markdown #Instance Type\n",
        "#@markdown **Google_Drive** = Stores Models, Images and the database in your Google drive, the space it takes up is hevily based on the type and number of models that you are using. <br>\n",
        "#@markdown **Temporary** = Everything is stored in the runtime and is removed when the runtime ends or crashes, make sure to download your images! <br>\n",
        "Type = \"Google_Drive\" #@param ['Google_Drive','Temporary'] {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown #Connection Type.\n",
        "#@markdown **NGROK**: (Recomended) Highly stable but needs a little setting up, An NGROK token is required, sign up for free and get one here: https://dashboard.ngrok.com/get-started/your-authtoken Once you have the token, please put it in below.<br>\n",
        "#@markdown **NGROK_APT**: An aternate version of NGROK that runs as a Linux service rather than a python service.<br>\n",
        "#@markdown **Localtunnel**: Stable once connected, but sometimes has issues.<br>\n",
        "connection_type = \"Localtunnel\"  #@param [\"Localtunnel\",\"NGROK\",\"NGROK_APT\"]\n",
        "ngrok_token = \"None\" #@param ['None'] {allow-input: true}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Models { display-mode: \"form\" }\n",
        "\n",
        "#@markdown ###All model mangement is all done in-app, the \"Model Manager\" is found on the left hand side once you are in the app. <br />\n",
        "#@markdown If you are using Temprory Mode, would you like to attach your Google Drive purely to import models from?\n",
        "GDrive_Import = \"No\" #@param [\"Yes\",\"No\"]\n",
        "\n",
        "#@markdown The path to the root of your Google drive will be added as: /content/drive/MyDrive/ You will use that in the \"Model manager\" to import models."
      ],
      "metadata": {
        "id": "g9611wcnE3e6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Advanced Options { display-mode: \"form\" }\n",
        "#@markdown ##These settings have all been removed. See below for details.\n",
        "\n",
        "#@markdown ##Version\n",
        "#@markdown Since Version 5.6.0+ Version control has been non-existant, this app updates on EVERY RUN now.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown #Model training.<br />\n",
        "#@markdown \"hollowstrawberry\" has an amazing Google colab LoRA maker, it is 100X Better than I could do! It can be found here:<br />\n",
        "#@markdown Dataset Maker - https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb <br />\n",
        "#@markdown LoRA Trainer - https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb"
      ],
      "metadata": {
        "id": "6WDsQHKoEj7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Build and Configure. { display-mode: \"form\" }\n",
        "#@markdown Install InvokeAI and configure it as requested, This takes around 2-4 mins.\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "#Setting File Path\n",
        "file_path = '/content/invokeai'\n",
        "\n",
        "#Set up temporary storage if running in \"Temporary\" mode.\n",
        "if Type == \"Temporary\":\n",
        "    import os\n",
        "    if not os.path.exists(file_path):\n",
        "      os.makedirs(file_path)\n",
        "\n",
        "    #Mount google drive for model imports if requested.\n",
        "    if GDrive_Import == \"Yes\":\n",
        "      import os\n",
        "      from google.colab import drive\n",
        "      if not os.path.exists('/content/drive/'):\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "# Mount and set up Google drive if running in \"Google_Drive\" mode.\n",
        "if Type == \"Google_Drive\":\n",
        "  import os\n",
        "  from google.colab import drive\n",
        "  if not os.path.exists(file_path):\n",
        "    drive.mount('/content/drive')\n",
        "    if not os.path.exists(file_path):\n",
        "      os.makedirs(file_path)\n",
        "\n",
        "#set working DIR\n",
        "%cd {file_path}\n",
        "\n",
        "#Clear Output\n",
        "clear_output()\n",
        "\n",
        "print(\"=======================\")\n",
        "print(\"|Install Dependencies.|\");\n",
        "print(\"=======================\")\n",
        "\n",
        "#Update pip\n",
        "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "!python -m pip install --upgrade pip\n",
        "\n",
        "#Install UV\n",
        "!pipx install uv\n",
        "\n",
        "#Create InvokeAI root\n",
        "import os\n",
        "os.environ['INVOKEAI_ROOT'] = file_path\n",
        "if not os.path.exists(file_path):\n",
        "  os.makedirs(invokeai_root)\n",
        "\n",
        "#Confirm that This is working in the correct place.\n",
        "%cd {file_path}\n",
        "\n",
        "#Clear Output\n",
        "clear_output()\n",
        "\n",
        "print(\"================================================================================\")\n",
        "print(\"|This is the first loading process for the App. It takes a few seconds to load.|\");\n",
        "print(\"================================================================================\")\n",
        "#%cd {file_path}\n",
        "!uv venv --relocatable --prompt invoke --python 3.11 --python-preference only-managed .venv\n",
        "!source .venv/bin/activate\n",
        "print(\" \")\n",
        "print(\"====================================================================================================================================================================================\")\n",
        "print(\"|This is the second loading process for the App. It takes on average 2-3 mins to load and has no indication of loading, for some reason if it displays the progress, Colab crashes!|\");\n",
        "print(\"====================================================================================================================================================================================\")\n",
        "!uv pip install invokeai[xformers] --python 3.11 --python-preference only-managed --force-reinstall &> /dev/null\n",
        "\n",
        "#This 'Deactivate' is needed incase you run this twice in one session where an update is released between runs, it will error 99% of the time.\n",
        "if os.path.exists(\"/content/RunSuccess\"):\n",
        "  print(\"This Deactivate only is needed on subsiquent runs. Ignore that it has errored. It will most of the time, and is a cleanup.\")\n",
        "  !deactivate\n",
        "  print(\"Deactivate command has been executed.\")\n",
        "if not os.path.exists(\"/content/RunSuccess\"):\n",
        "  !touch \"/content/RunSuccess\"\n",
        "\n",
        "!source .venv/bin/activate\n",
        "\n",
        "if Type == \"Google_Drive\":\n",
        "  print(\" \")\n",
        "  print(\"==================================================================================================\")\n",
        "  print(\"|This is the third loading process for the App, setting the program up for 'Google Drive' storage|\");\n",
        "  print(\"==================================================================================================\")\n",
        "  !echo \"# Internal metadata - do not edit:\" > /content/invokeai/invokeai.yaml\n",
        "  !echo \"schema_version: 4.0.2\" >> /content/invokeai/invokeai.yaml\n",
        "  !echo \" \" >> /content/invokeai/invokeai.yaml\n",
        "  !echo \"# Put user settings here - see https://invoke-ai.github.io/InvokeAI/configuration/:\" >> /content/invokeai/invokeai.yaml\n",
        "  !echo \"models_dir: /content/drive/MyDrive/InvokeAI/Models\" >> /content/invokeai/invokeai.yaml\n",
        "  !echo \"outputs_dir: /content/drive/MyDrive/InvokeAI\" >> /content/invokeai/invokeai.yaml\n",
        "  !echo \"db_dir: /content/drive/MyDrive/InvokeAI/DB\" >> /content/invokeai/invokeai.yaml\n",
        "  !echo \"enable_partial_loading: true\" >> /content/invokeai/invokeai.yaml\n",
        "  print(\"Locations set for Google Drive!\");\n",
        "\n",
        "if Type == \"Temporary\":\n",
        "  print(\" \")\n",
        "  print(\"===============================================================================================\")\n",
        "  print(\"|This is the third loading process for the App, setting the program up for 'Temporary' storage|\");\n",
        "  print(\"===============================================================================================\")\n",
        "  !echo \"# Internal metadata - do not edit:\" > /content/invokeai/invokeai.yaml\n",
        "  !echo \"schema_version: 4.0.2\" >> /content/invokeai/invokeai.yaml\n",
        "  !echo \" \" >> /content/invokeai/invokeai.yaml\n",
        "  !echo \"# Put user settings here - see https://invoke-ai.github.io/InvokeAI/configuration/:\" >> /content/invokeai/invokeai.yaml\n",
        "  !echo \"enable_partial_loading: true\" >> /content/invokeai/invokeai.yaml\n",
        "  print(\"Locations set for Temporary Storage!\");\n",
        "\n",
        "print(\" \")\n",
        "print(\"=============================\")\n",
        "print(\"|Done! Launch the app below!|\")\n",
        "print(\"=============================\")"
      ],
      "metadata": {
        "id": "NO3XyDPsTJ2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnO01U-W6Yjp"
      },
      "outputs": [],
      "source": [
        "#@title 5. Start InvokeAI. { display-mode: \"form\" }\n",
        "#@markdown ## Starting the App\n",
        "#@markdown This step takes about 15 seconds to generate your URL but 30 seconds after it is launched before it will work fully! <br>\n",
        "\n",
        "#@markdown ## Notes about connection types.\n",
        "#@markdown **NGROK** (Recomneded) = Very stable but requires a token, see the \"configuration\" step for more details.<br>\n",
        "#@markdown **NGROK_APT** = An alternate version of NGROK that runs using the system packages rather than Python. <br>\n",
        "#@markdown **Localtunnel** = Once it gets going it is quite stable but often has \"502\" Errors, You must wait for THEM to fix it, please try another connection type.<br>\n",
        "#@markdown **Serveo** = Removed, No longer Exists.\n",
        "\n",
        "!source .venv/bin/activate\n",
        "\n",
        "%cd {file_path}\n",
        "import os\n",
        "\n",
        "#Clear Output\n",
        "clear_output()\n",
        "\n",
        "#Serveo is broken Keeping this code incase it comes back.\n",
        "#if connection_type == \"Serveo\":\n",
        "  #!ssh -o StrictHostKeyChecking=no -o ServerAliveInterval=60 -R 80:localhost:9090 serveo.net & ! . {file_path}/.venv/bin/activate; invokeai-web\n",
        "\n",
        "if connection_type == \"Localtunnel\":\n",
        "  print(\"How to connect to localtunnel:\");\n",
        "  print(\"A localtunnel Interface connection is generated here, To use this, please do the following \")\n",
        "  print(\"1. Copy this IP address\")\n",
        "  !curl ipv4.icanhazip.com\n",
        "  print(\"2. Click the random 'https://XXX-YYY-ZZZ.loca.lt' link that is generated below.\")\n",
        "  print(\"3. Paste the IP into the provided box and submit. \")\n",
        "  print(\" \")\n",
        "  print(\"Note: An error of '502 Bad Gateway' typically is an error at Localtunnels end. A '504 Gateway Time-out' Error means invokeai has not started yet.\")\n",
        "  print(\" \")\n",
        "  !npm install -g localtunnel\n",
        "  !lt --port 9090 & ! . {file_path}/.venv/bin/activate; invokeai-web\n",
        "\n",
        "\n",
        "#NGROK_Python\n",
        "if connection_type == \"NGROK\":\n",
        "  if ngrok_token == \"None\":\n",
        "    print(\"You have Selected NGROK but did not supply an NGROK token.\")\n",
        "    print(\"Falling back to a 'Localtunnel' connection type.\")\n",
        "    print(\"Please either add an NGROK token to step 1, re-run step 1, then re-run this step, or just re-run this step to use 'Servio'.\")\n",
        "    connection_type = \"Localtunnel\"\n",
        "  if ngrok_token != \"None\":\n",
        "    !pip install pyngrok --quiet\n",
        "    from pyngrok import ngrok\n",
        "    ngrok.kill()\n",
        "    ngrok.set_auth_token(ngrok_token)\n",
        "    public_url = ngrok.connect(9090).public_url\n",
        "    print(f'InvokeAI Public URL: {public_url}')\n",
        "    ! . {file_path}/.venv/bin/activate; invokeai-web\n",
        "\n",
        "#NGROK_APT\n",
        "if connection_type == \"NGROK_APT\":\n",
        "  if ngrok_token == \"None\":\n",
        "    print(\"You have Selected NGROK but did not supply an NGROK token.\")\n",
        "    print(\"Falling back to a 'Localtunnel' connection type.\")\n",
        "    print(\"Please either add an NGROK token to step 1, re-run step 1, then re-run this step, or just re-run this step to use 'Servio'.\")\n",
        "    connection_type = \"Localtunnel\"\n",
        "  if ngrok_token != \"None\":\n",
        "    !curl -sSL https://ngrok-agent.s3.amazonaws.com/ngrok.asc | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null\n",
        "    !echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" | sudo tee /etc/apt/sources.list.d/ngrok.list\n",
        "    !sudo apt update\n",
        "    !sudo apt install ngrok\n",
        "    !ngrok config add-authtoken {ngrok_token}\n",
        "    clear_output()\n",
        "    !echo \"You can find the connection URL here in the NGROK portal:\"\n",
        "    !echo \"https://dashboard.ngrok.com/endpoints\"\n",
        "    !nohup ngrok http http://localhost:9090 &\n",
        "    ! . {file_path}/.venv/bin/activate; invokeai-web"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FAQ:\n",
        "\n",
        "## Images are taking a LONG time to generate. (~30 mins for a 512x512 image.)\n",
        "You may have used up your computer allowance and are running in CPU mode. While this is running click the \"RAM / Disk\" button in the top right to see if it lists \"GPU RAM\" If not, you are not connected to a GPU instance.\n",
        "or maybe, you have the GPU turned off, check \"Edit > Notebook settings\" to make sure a GPU is selected. (\"T4 GPU\" is the current default)\n",
        "\n",
        "## It is taking a while to even start loading.\n",
        "If you have started a new instance / are changing a model. the model needs to be loaded into Invoke. If you are using \"Google Drive\" It has to download the model to the runtime, this can take a while especially for XL (5-10 mins) or FLUX models (20+ mins)\n",
        "\n",
        "## I get an error \"You have recently exceeded an allowance, most recently at (Time)\"\n",
        "This is typically when you have exceeded some Google restriction(s). This is most common when you stop / start instances frequently and often does not affect anything. <br>\n",
        "If it is blocking things, you typically have to wait 1 hour for soft allowances to reset.  \n",
        "\n",
        "##How much longer can my instance run for today?\n",
        "If you click the RAM / DISK\" button in the top right it will tell you something like \"At your current usage level, this runtime may last up to 1 hour 20 minutes\"\n",
        "\n",
        "## My instance disconnects while I'm using it.\n",
        "Technically using Web interface to run programs in a way like this project does, is against Google Collab's Terms of Service. If you don't look at this tab for 15+ mins it may hibernate. Simply flick back to this tab on a semi-regular basis to keep it active!\n",
        "\n",
        "## Are there any known issues?\n",
        "If there are, I will typically update the header at the top of this page above the \"Introduction\".\n",
        "\n",
        "## I want to make my own changes to this file, and save them.\n",
        "Feel free to! \"File > Save a copy in drive\" is the safest way to do this.\n",
        "\n",
        "## Is this maintained frequently?\n",
        "I am a solo dev that maintains it the best that I can, I do use this project frequently so hopefully I will notice any major issues. <br>\n",
        "If you have any issues you can raise them on Github I will deal with them when I can! <br>\n",
        "https://github.com/MikeEmmett/InvokeAI/issues\n",
        "\n",
        "## I am using Google Drive and I want to reset everything.\n",
        "If you log onto https://drive.google.com/drive/my-drive with your Google account you will find a folder called \"InvokeAI\" <br>\n",
        "If you just want to reset it without keeping anything, simply delete the whole folder. <br>\n",
        "If you want to reset it but keep the models / Images in an archive, rename the folder.\n",
        "\n",
        "## I don't understand the options above...\n",
        "Experiment! This will work fully if you just do \"Runtime > Run all\" It will connect to your Google Drive and spin up a \"Localtunnel\" connection and just simply copy the IP address / paste into the link as instructed in the last step! Also feel free to play around, you can't break things permanently!"
      ],
      "metadata": {
        "id": "2dccS8zX9wHK"
      }
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}